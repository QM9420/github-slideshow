import pandas as pd
import numpy as np
from LSTM import *
import  torch
from torch.utils.data import TensorDataset,DataLoader,Dataset
from torch import nn

# 数据
data_path = '7/test%d.xlsx' % (2)  # LSTM_DATA/1.xlsx

# 读取文件
df = pd.read_excel(data_path)
data = df.to_numpy()
height,width = data.shape


# Hyper Parameters
EPOCH = 250     # 训练整批数据多少次
BATCH_SIZE = 1
TIME_STEP =  width   #  时间 步数 / 样本数
INPUT_SIZE = height-2      #  每 步输入值 / 特征数
HIDDEN_SIZE = 36 # 隐藏层
NUM_LAYER = 2       # LSTM层数
LR = 0.01        # l earning rate
ACCS,accs = [],[]
rcs,RCS = [],[]
w0,w1,w2 = [],[],[]
'''
20 2 accuracy: [0.8549618320610687, 0.76335877862 59542, 0.8091603053435115, 0.9694656488549618, 0.7862595419847328]
accuracy: [0.8244274809160306, 0.7938931297709924, 0.8396946564885496, 0.7862595419847328, 0.916030534351145]
24 2 accuracy: [0.8931297709923665, 0.8015267175572519, 0.9541984732824428, 0.9694656488549618, 0.7938931297709924]
accuracy: [0.9465648854961832, 0.8549618320610687, 0.9541984732824428, 0.9847328244274809, 0.9770992366412213]
28 2 accuracy: [0.916030534351145, 0.816793893129771, 0.7709923664122137, 0.9465648854961832, 0.8320610687022901]
accuracy: [0.9007633587786259, 0.9541984732824428, 0.9618320610687023, 0.9007633587786259, 0.9007633587786259]
32 ,2 accuracy: [0.9236641221374046, 0.9541984732824428, 0.7480916030534351, 0.9541984732824428, 0.8854961832061069]
[0.7938931297709924, 0.9083969465648855, 0.7938931297709924, 0.8702290076335878, 0.8396946564885496]
36 2 accuracy: [0.9236641221374046, 0.9007633587786259, 0.9312977099236641, 0.9694656488549618, 0.9465648854961832]
accuracy: [0.8396946564885496, 0.9236641221374046, 0.8396946564885496, 0.8931297709923665, 0.8778625954198473]
40,2 accuracy: [0.816793893129771, 0.8015267175572519, 0.7557251908396947, 0.9923664122137404, 0.7938931297709924]
accuracy: [0.8015267175572519, 0.8931297709923665, 0.9465648854961832, 0.8015267175572519, 0.8396946564885496]
'''
'''
20 3 200 accuracy: [0.9007633587786259, 0.7938931297709924, 0.7709923664122137, 0.816793893129771, 0.7709923664122137]
accuracy: [0.9465648854961832, 0.75572519083969 47, 0.8854961832061069, 0.8549618320610687, 0.8091603053435115]
20 3 300 accuracy: [0.8473282442748091, 0.7786259541984732, 0.7786259541984732, 1.0, 0.9770992366412213]
accuracy: [0.8931297709923665, 0.9236641221374046, 0.9465648854961832, 0.9770992366412213, 0.7938931297709924]
24 3 300 accuracy: [0.8320610687022901, 0.8702290076335878, 0.9618320610687023, 0.7557251908396947, 0.7557251908396947]
accuracy: [0.8778625954198473, 0.816793893129771, 0.7709923664122137, 0.9312977099236641, 0.9083969465648855]
24 3 200 accuracy: [0.7862595419847328, 0.8549618320610687, 0.7938931297709924, 0.9389312977099237, 0.7404580152671756]
accuracy: [0.7633587786259542, 0.8854961832061069, 0.9847328244274809, 0.7251908396946565, 0.7862595419847328]
28 3 200 accuracy: [0.9618320610687023, 0.9236641221374046, 0.7633587786259542, 0.9312977099236641, 0.8473282442748091]
accuracy: [0.8702290076335878, 0.7938931297709924, 0.9389312977099237, 0.8702290076335878, 0.7404580152671756]
28 3 300  accuracy: [0.732824427480916, 0.732824427480916, 0.8320610687022901, 0.7557251908396947, 0.9541984732824428]
accuracy: [0.9083969465648855, 0.7633587786259542, 0.8396946564885496, 0.816793893129771, 0.7938931297709924]
32 3 300 [0.8931297709923665, 0.8778625954198473, 0.9541984732824428, 0.9541984732824428, 0.7022900763358778]
accuracy: [0.9770992366412213, 0.7251908396946565, 0.916030534351145, 0.816793893129771, 0.7404580152671756]
32 3 200 accuracy: [0.9694656488549618, 0.7938931297709924, 0.7404580152671756, 0.9694656488549618, 0.9694656488549618]
accuracy: [0.8778625954198473, 0.816793893129771, 0.9465648854961832, 0.7709923664122137, 0.9083969465648855]
36 3 200 accuracy: [0.7862595419847328, 0.7557251908396947, 0.7709923664122137, 0.7862595419847328, 0.8091603053435115]
accuracy: [0.8320610687022901, 0.8015267175572519, 0.9007633587786259, 0.9465648854961832, 0.8854961832061069]
36 3 300 accuracy: [0.9541984732824428, 0.9465648854961832, 0.7938931297709924, 0.7938931297709924, 0.7709923664122137]
accuracy: [0.8702290076335878, 0.7786259541984732, 0.9312977099236641, 0.7938931297709924, 0.8015267175572519]
40 3 300 accuracy: [0.8931297709923665, 0.8015267175572519, 0.8549618320610687, 0.916030534351145, 0.8015267175572519]
accuracy: [0.9618320610687023, 0.9312977099236641, 0.7709923664122137, 0.9541984732824428, 0.9618320610687023]
400 3 200 [0.7557251908396947, 0.8091603053435115, 0.7404580152671756, 0.9618320610687023, 0.7557251908396947]
accuracy: [0.8091603053435115, 0.8015267175572519, 0.9618320610687023, 0.9083969465648855, 0.8854961832061069]
'''
'''
36 2 200 1 :2 accuracy: [0.8396946564885496, 0.7938931297709924, 0.8549618320610687, 0.8549618320610687, 0.9770992366412213]
 [0.8320610687022901, 0.8015267175572519, 0.9465648854961832, 0.9541984732824428, 0.9465648854961832]
36 2 200 1:3 accuracy: [0.7480916030534351, 0.7709923664122137, 0.9236641221374046, 0.9618320610687023, 0.7709923664122137]
accuracy: [0.816793893129771, 0.9770992366412213, 0.9694656488549618, 0.8778625954198473, 0.9541984732824428]
accuracy: [0.7709923664122137, 0.9465648854 961832, 0.8244274809160306, 0.8931297709923665, 0.7786259541984732]
36 2 200 1:4 accuracy: [0.8625954198473282, 0.9618320610687023, 0.7404580152671756, 0.8931297709923665, 0.7709923664122137]
accuracy: [0.9389312977099237, 0.9083969465648855, 0.9312977099236641, 0.9083969465648855, 0.8473282442748091]
accuracy: [0.7633587786259542, 0.9541984732824428, 0.8396946564885496, 0.9389312977099237, 0.8549618320610687]
36 2 200 1:5 accuracy: [0.9389312977099237, 0.9694656488549618, 0.9465648854961832, 0.8015267175572519, 0.916030534351145]
accuracy: [0.8473282442748091, 0.9541984732824428, 0.7862595419847328, 0.9618320610687023, 00.9007633587786259]
accuracy: [0.9618320610687023, 0.9389312977099237, 0.9694656488549618, 0.9312977099236641, 0.8473282442748091]
36 2 200 1:6 accuracy: [0.9541984732824428, 0.7480916030534351, 0.7633587786259542, 0.9541984732824428, 0.8702290076335878]
accuracy: [0.9465648854961832, 0.9465648854961832, 0.9236641221374046, 0.9770992366412213, 0.8015267175572519]
accuracy: [0.9465648854961832, 0.816793893129771, 0.8396946564885496, 0.8931297709923665, 0.8244274809160306]
accuracy: [0.9694656488549618, 0.8854961832061069, 0.7786259541984732, 0.816793893129771, 0.9618320610687023]
accuracy: [0.7557251908396947, 0.8396946564885496, 0.8625954198473282, 0.8931297709923665, 0.9541984732824428]
36 2 200 1:7 [0.8549618320610687, 0.9770992366412213, 0.916030534351145, 0.9694656488549618, 0.8778625954198473]
accuracy: [0.7557251908396947, 0.9312977099236641, 0.7709923664122137, 0.9541984732824428, 0.916030534351145]
accuracy: [0.7938931297709924, 0.9541984732824428, 0.9618320610687023, 0.9389312977099237, 0.8931297709923665
accuracy: [0.8549618320610687, 0.9312977099236641, 0.8625954198473282, 0.9694656488549618, 0.816793893129771]
'''
'''
36 2 200 1:5 accuracy: [0.9389312977099237, 0.9694656488549618, 0.9465648854961832, 0.8015267175572519, 0.916030534351145]
accuracy: [0.8473282442748091, 0.9541984732824428, 0.7862595419847328, 0.9618320610687023, 00.9007633587786259]
accuracy: [0.9618320610687023, 0.9389312977099237, 0.9694656488549618, 0.9312977099236641, 0.8473282442748091]
accuracy: [0.8320610687022901, 0.9770992366412213, 0.9236641221374046, 0.7404580152671756, 0.7633587786259542]
35 2 200 1:5 accuracy: [0.9465648854961832, 0.916030534351145, 0.9389312977099237, 0.9694656488549618, 0.8549618320610687]
accuracy: [0.9312977099236641, 0.8320610687022901, 0.7938931297709924, 0.9312977099236641, 0.8015267175572519]
accuracy: [0.7938931297709924, 0.7786259541984732, 0.9236641221374046, 0.9618320610687023, 0.7938931297709924

34 2 200 1:5  [0.9694656488549618, 0.8396946564885496, 0.8778625954198473, 0.7786259541984732, 0.8702290076335878]
accuracy: [0.9312977099236641, 0.9312977099236641, 0.916030534351145, 0.9618320610687023, 0.816793893129771]

33 2 200 1:5 accuracy: [0.93 12977099236641, 0.8854961832061069, 0.8091603053435115, 0.7786259541984732, 0.9541984732824428]
accuracy: [0.9694656488549618, 0.7786259541984732, 0.7709923664122137, 0.9694656488549618, 0.9312977099236641]
accuracy: [0.9694656488549618, 0.9007633587786259, 0.9389312977099237, 0.8244274809160306, 0.9007633587786259]

37 2 200 1-5 accuracy: [0.8854961832061069, 0.9618320610687023, 0.9007633587786259, 0.9236641221374046, 0.9312977099236641]
accuracy: [0.9312977099236641, 0.9694656488549618, 0.8091603053435115, 0.9465648854961832, 0.9847328244274809]
accuracy: [0.847328244274 8091, 0.7404580152671756, 0.9389312977099237, 0.9618320610687023, 0.8473282442748091]
accuracy: [0.9618320610687023, 0.8778625954198473, 0.7633587786259542, 0.9465648854961832, 0.8625954198473282]

38 2 200 1-5 accuracy: [0.9312977099236641, 0.8702290076335878, 0.8778625954198473, 0.7633587786259542, 0.7557251908396947]
accuracy: [0.8625954198473282, 0.7938931297709924, 0.9312977099236641, 0.8091603053435115, 0.9618320610687023]

39 2 200 1-5 accuracy: [0.7786259541984732, 0.8396946564885496, 0.9541984732824428, 0.8854961832061069, 0.8091603053435115]
accuracy: [0.8244274809160306, 0.8854961832061069, 0.9541984732824428, 0.7938931297709924, 0.816793893129771]
'''
for i in range(10):
#训练数据和测试数据
    data = data_shuffle(data)


    print("INPUTSIZE",height-2)

    dataset_x,dataset_y,dataset_target = create_dataset1(data)

    # print(sum(dataset_y))  #102个负样本

    # print("width",width)
    # leny = len(dataset_y)
    num_train = int(width * 0.7)
    num_test = width - num_train
    # num_trainy = leny * 0.7


    train_x = dataset_x[:num_train]
    train_y = dataset_y[:num_train]
    train_t = dataset_target[:num_train]

    test_x = dataset_x[num_train:]
    test_y = dataset_y[num_train:]
    test_t = dataset_target[num_train:]

    '''
    train_x = dataset_x[num_test:]
    train_y = dataset_y[num_test:]
    
    test_x = dataset_x[:num_test]
    test_y = dataset_y[:num_test]
    '''
    # print("测试集样本标签：",test_t)
    print("测试集数量",test_y.shape)   # 131     131   44
    print("测试集中负样本数量",sum(test_y))      # 61     6    23
    test_num = len(test_y)
    # print("test_num",test_num)  # 131
    # print("train_num",num_train)  # 304
    #转换为模型的形式 （batchsize,timestep,inputsize）
    train_x = train_x.reshape(-1,BATCH_SIZE,INPUT_SIZE)
    train_y = train_y.reshape(-1,BATCH_SIZE,1)
    train_x = torch.from_numpy(train_x)
    train_y = torch.from_numpy(train_y)
    train_y = train_y.to(torch.long)

    test_x = test_x.reshape(-1,BATCH_SIZE,INPUT_SIZE)
    test_x = torch.from_numpy(test_x)
    test_x = test_x.to(torch.float32)
    # test_y = test_y.reshape(-1,BATCH_SIZE,1)
    # test_y = torch.from_numpy(test_y)
    # test_y = test_y.to(torch.long)
    # test_y = test_y.view(-1)

    dataset_train = TensorDataset(train_x,train_y)
    dataset_train = dataset_train
    train_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=BATCH_SIZE, shuffle=True)

    model = LSTM_classifier(INPUT_SIZE,HIDDEN_SIZE,NUM_LAYER)
    optimizer = torch.optim.Adam(model.parameters(), lr=LR)   # optimize all parameters

    weight_ce = torch.FloatTensor([1,5])
    loss_func = nn.CrossEntropyLoss(weight=weight_ce)   # the target label is not one-hotted



    # training and testing
    for epoch in range(EPOCH):
        for step, (x, b_y) in enumerate(train_loader):   # gives batch data
            b_x = x.view(-1, BATCH_SIZE, INPUT_SIZE)   # reshape x to (batch, time_step, input_size)
            b_x = b_x.to(torch.float32)

            output = model(b_x)               # rnn output

            # output = torch.max(output, 1)
            b_y = b_y.view(-1)
            # print(b_y)
            # b_y = b_y.squeeze(1).long()

            # print("b_y的shape：",b_y.size())   # torch.Size([1, 1, 1])
            # print(b_x.size())   # torch.Size([1, 1, 46])
            # print(output)   # torch.Size([1, 2])

            loss = loss_func(output, b_y)   # cross entropy loss


            optimizer.zero_grad()           # clear gradients for this training step
            loss.backward()                 # backpropagation, compute gradients
            optimizer.step()                # apply gradients

            if epoch % 100 == 0 and step % 100 == 0:

                print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy())


    model = model.eval()
    out1 = model(test_x)
    out1 = out1.data.numpy()
    # print(out1)
    # print(out1.shape)
    prediction = np.argmax(out1,axis=1)

    # print(prediction)

    # print(test_y)
    results = prediction-test_y
    print(results)

    P = sum(test_y)
    TP = P - np_count(results,-1)
    RC = TP/P
    rcs.append(RC)
    RCS.append(RC)
    print("测试负样本：",sum(test_y))
    print("错误：",sum(np.abs(results)))
    # print(prediction.shape)
    w0,w1,w2 = check_wrong(test_t,results,w0,w1,w2)

    accuracy = sum(prediction == test_y) / test_num

    accs.append(accuracy)
    ACCS.append(accuracy)
    if((i+1) % 10 == 0):
        print("accuracy:",accs)
        print("RC",rcs)
        accs = []
        rcs = []

w0 = np.array(w0)
w1 = np.array(w1)
w2 = np.array(w2)
ACCS = np.array(ACCS)
RCS = np.array(RCS)

write_excel4(w0, 0)
write_excel4(w1, 1)
write_excel4(w2, 2)
write_excel4(ACCS,7)
write_excel4(RCS,8)
